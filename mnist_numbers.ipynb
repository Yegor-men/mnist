{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "f72de16c071a5f15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "fb8dfc6445887be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model architecture",
   "id": "5e9ae9443dcf1886"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN encoder",
   "id": "d5b6bbb8aae5133a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int):\n",
    "        \"\"\"\n",
    "        Encodes the 28*28 image vid a CNN network into hidden_channels channels of 7*7 representation.\n",
    "        :param in_channels: how many color channels the image has.\n",
    "        :param hidden_channels: how many channels the image should be encoded into.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.lrelu = nn.ReLU()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.Conv2d(in_channels=hidden_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.Conv2d(in_channels=hidden_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block_2(x)\n",
    "        return x\n"
   ],
   "id": "9818ace9e33a96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear decoder",
   "id": "6fc83e5041595f8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_classes: int, hidden_channels: int):\n",
    "        \"\"\"\n",
    "        Decodes (classifies) the encoded image into one of output_classes classes.\n",
    "        :param output_classes: how many classes the image could have.\n",
    "        :param hidden_channels: how many hidden channels the image should be decoded from.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_channels * 7 * 7,\n",
    "                      out_features=output_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "id": "dca18ee26e0a84fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Combined model",
   "id": "8c4929bf3b2fbee7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channels: int, output_classes: int, hidden_channels: int):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_channels=in_channels, hidden_channels=hidden_channels)\n",
    "        self.decoder = Decoder(hidden_channels=hidden_channels, output_classes=output_classes).to(device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model(in_channels=1,\n",
    "              output_classes=10,\n",
    "              hidden_channels=10).to(device=device)"
   ],
   "id": "6d41db62af01f9a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training data",
   "id": "8ed5ce30ae95c7fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(root='mnist_data',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=ToTensor(),\n",
    "                            target_transform=None)\n",
    "\n",
    "test_data = datasets.MNIST(root='mnist_data',\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=ToTensor(),\n",
    "                           target_transform=None)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n"
   ],
   "id": "307793928abc125b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Loop",
   "id": "a8662a5c55a5ff97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 0.01\n",
    "UPDATE_PARAMETERS_EVERY = 1\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "current_batch = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for train_batch_index, (x_train, y_train) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = x_train.to(device=device), y_train.to(device=device)\n",
    "        train_outputs = model(x_train)\n",
    "        loss = loss_fn(train_outputs, y_train)\n",
    "        train_loss_history.append(loss.item())\n",
    "        current_batch += 1\n",
    "        print(f\"E {epoch + 1:,}/{EPOCHS:,} | Batch {train_batch_index + 1:,}/{len(train_dataloader):,} | Loss: {loss.item():,}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        for test_batch_index, (x_test, y_test) in enumerate(test_dataloader):\n",
    "            x_test, y_test = x_test.to(device=device), y_test.to(device=device)\n",
    "            test_outputs = model(x_test)\n",
    "            test_loss = loss_fn(test_outputs, y_test)\n",
    "            test_loss_history.append(test_loss.item())\n",
    "            print(f\"E {epoch + 1:,}/{EPOCHS:,} | Test batch {test_batch_index + 1:,}/{len(test_dataloader):,} | Loss: {test_loss.item():,}\")\n",
    "\n",
    "train_x = np.arange(len(train_loss_history))  # Train loss x-axis\n",
    "test_x = np.linspace(0, len(train_loss_history)-1, len(test_loss_history))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_x, train_loss_history, label='Train Loss', marker='o')\n",
    "plt.plot(test_x, test_loss_history, label='Test Loss', marker='s')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "ac9398650f480b4b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
