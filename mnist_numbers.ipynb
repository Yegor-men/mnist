{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "f72de16c071a5f15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# torch.set_default_device(\"cpu\")\n",
    "# torch.set_default_dtype(torch.float16)"
   ],
   "id": "fb8dfc6445887be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model architecture",
   "id": "5e9ae9443dcf1886"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN encoder",
   "id": "d5b6bbb8aae5133a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int):\n",
    "        \"\"\"\n",
    "        Encodes the 28*28 image vid a CNN network into hidden_channels channels of 7*7 representation.\n",
    "        :param in_channels: how many color channels the image has.\n",
    "        :param hidden_channels: how many channels the image should be encoded into.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.lrelu = nn.ReLU()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.Conv2d(in_channels=hidden_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.Conv2d(in_channels=hidden_channels,\n",
    "                      out_channels=hidden_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            self.lrelu,\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block_2(x)\n",
    "        return x\n"
   ],
   "id": "9818ace9e33a96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear decoder",
   "id": "6fc83e5041595f8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_classes: int, hidden_channels: int):\n",
    "        \"\"\"\n",
    "        Decodes (classifies) the encoded image into one of output_classes classes.\n",
    "        :param output_classes: how many classes the image could have.\n",
    "        :param hidden_channels: how many hidden channels the image should be decoded from.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_channels * 7 * 7,\n",
    "                      out_features=output_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "id": "dca18ee26e0a84fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Combined model",
   "id": "8c4929bf3b2fbee7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channels: int, output_classes: int, hidden_channels: int):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_channels=in_channels, hidden_channels=hidden_channels)\n",
    "        self.decoder = Decoder(hidden_channels=hidden_channels, output_classes=output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model(in_channels=1,\n",
    "              output_classes=10,\n",
    "              hidden_channels=10)"
   ],
   "id": "6d41db62af01f9a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training data",
   "id": "8ed5ce30ae95c7fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(root='mnist_data',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=ToTensor(),\n",
    "                            target_transform=None)\n",
    "\n",
    "test_data = datasets.MNIST(root='mnist_data',\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=ToTensor(),\n",
    "                           target_transform=None)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n"
   ],
   "id": "307793928abc125b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Loop",
   "id": "a8662a5c55a5ff97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "UPDATE_PARAMETERS_EVERY_NUM_BATCHES = 1\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "train_accuracy_history = []\n",
    "test_accuracy_history = []\n",
    "current_batch = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    train_loss, test_loss = 0, 0\n",
    "    train_accuracy, test_accuracy = 0, 0\n",
    "\n",
    "    for train_batch_index, (X_batch, Y_batch) in enumerate(train_dataloader):\n",
    "        x_batch, y_batch = X_batch, Y_batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        train_loss += loss.item() * len(y_batch)\n",
    "        current_batch += 1\n",
    "        loss.backward()\n",
    "\n",
    "        if current_batch % UPDATE_PARAMETERS_EVERY_NUM_BATCHES == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            current_batch = 0\n",
    "\n",
    "        print(\n",
    "            f\"E {epoch + 1:,}/{EPOCHS:,} | Batch {train_batch_index + 1:,}/{len(train_dataloader):,} | Loss: {loss.item():,}\")\n",
    "\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        for index, prediction in enumerate(predictions):\n",
    "            if prediction == y_batch[index]:\n",
    "                train_accuracy += 1\n",
    "\n",
    "    train_loss /= len(train_data)\n",
    "    train_accuracy /= len(train_data)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        for test_batch_index, (X_batch, Y_batch) in enumerate(test_dataloader):\n",
    "            x_batch, y_batch = X_batch, Y_batch\n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            test_loss += loss.item() * len(y_batch)\n",
    "\n",
    "            print(\n",
    "                f\"E {epoch + 1:,}/{EPOCHS:,} | Test batch {test_batch_index + 1:,}/{len(test_dataloader):,} | Loss: {loss.item():,}\")\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            for index, prediction in enumerate(predictions):\n",
    "                if prediction == y_batch[index]:\n",
    "                    test_accuracy += 1\n",
    "\n",
    "    test_loss /= len(test_data)\n",
    "    test_accuracy /= len(test_data)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.plot(train_loss_history, label='Train Loss')\n",
    "ax1.plot(test_loss_history, label='Test Loss')\n",
    "ax1.title.set_text('Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(train_accuracy_history, label='Train Accuracy')\n",
    "ax2.plot(test_accuracy_history, label='Test Accuracy')\n",
    "ax2.title.set_text('Training Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "ac9398650f480b4b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
